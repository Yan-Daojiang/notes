# 数据存储与检索
数据库在插入数据时，就保存数据，而在查询时，就检索数据。数据是如何存储，查询时，又是如何进行检索的呢？这就涉及到数据库内部的实现了。尽管现在不用从头开发一套新的存储引擎，但是了解相关的知识能够让我们针对特定的场景选择合适的存储引擎，针对一些数据库进行调优时，也需要对底层的存储引擎有一个基本了解。不同的场景和需求下，存储引擎也会做不同的优化，例如针对事务型负载（OLTP）和分析型（OLAP）负载的存储引擎就存在巨大差异。在 OLTP 方面，存储引擎又可以分为两大家族：面向日志结构的存储引擎和面向页的存储引擎。

## 数据库的核心：数据结构
最简单的数据库原理如下，类似日志（log），每次插入数据时就追加到文件的尾部，而查询数据时，则在文件中倒查。
```Shell
#!/bin/bash

db_set () {
    echo "$1,$2" >> database
}

db_get () {
    grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```
然而，这个数据库存在很多问题，其中最常见的就是其查询数据的性能太低，它的查找开销是 O(n)。

为了提高查询的性能，通常会新的数据结构：索引。索引是通过保留一些额外的元数据，并通过它们来定位需要查找的数据，根据查找的方式不同可以建立不同的索引。尽管索引的引入能够提高查询的性能，然而，索引的维护是需要额外的开销的，特别是在新数据写入的时候，需要更新索引，因而任何类型的索引通常都会降低写入的速度。因此，在设计的时候也就需要就此进行权衡，适当的索引能够加速读取的速度，但是同时又会降低写入速度。

### 哈希索引
最容易想到的是键-值（key-value, kv）数据的索引，因为它和编程语言中的字典结构类似，可以很容易的将它扩展到磁盘上索引数据。

最简单的策略就是：保存内存中的 hash map，可以将每个键映射为文件特定字节的偏移量（文件中的存储位置），通过这样的方式能够提供高性能的读写，只需磁盘寻址一次，如果操作系统已经缓存了那部分文件数据，在读取的时候甚至可以避免磁盘I/O。这种模式下存储引擎，非常适合一定规模的键存储需求，同时值需要频繁更新的场景。

上面这种模式在写数据的时候，如果只是不断追加一个文件那么该如何避免磁盘空间用尽呢？一种好的解决方式就是日志分解为一定大小的段，每个段使用自己的内存哈希表。当段文件达到一定的大小的时候就关闭，后续的写入使用新的文件，已经关闭的文件段可以进行压缩合并。该过程可以使用后台线程去完成，在运行的时候，旧的段文件可以继续处理读写请求，合并完成之后，切换到新的文件，并可以将旧的文件安全删除。

从理论上看哈希索引似乎非常简单，然而，在真；正的实现中还需要考虑下面一些重要问题：
* 文件格式：应当使用合适的文件格式来存储值；
* 记录删除：删除某个键关联的值的时候需要在数据库文件中设置特殊的删除记录（称为墓碑）。合并的过程中，一旦碰到墓碑，就应该丢弃这个已删键的所有值；
* 崩溃恢复：数据库重启，内存中的哈希表将丢失，理论上可以通过文件重建哈希表，但是在段文件很大的时候可能需要很长的时间恢复。通过快照等方式能够加快恢复的速度；
* 部分写入问题：数据库系统可能在任何时候崩溃，因此可能造成部分写入问题，常见的解决方式又写入校验值等；
* 并发控制：写入需要以严格的顺序写入到日志文件中，通常仅设置一个写入线程，并且文件是只追加的，这样可以被多个线程同时读取。

哈希索引看起来很好，但是也有其天然的局限性：
* 哈希索引需要所有的键被保存在内存中，当键的数量巨大时，将很难进行处理。目前，在磁盘上很难维护哈希表，主要是其需要大量的随机I/O。
* 哈希索引并不适合区间查询。
为了突破这些限制，需要一些其他的索引结构。
